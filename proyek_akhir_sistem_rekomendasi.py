# -*- coding: utf-8 -*-
"""Proyek Akhir - Sistem Rekomendasi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ifdOTTo1BUj39pzMtLXA87U0JbvQcVTw

# **Sistem Rekomendasi Tempat Wisata - Submission Machine Learning Terapan**

### **Project Overview**

Pariwisata di Indonesia merupakan sektor ekonomi yang penting di Indonesia. Di tahun 2019, pariwisata menduduki peringkat ke-tiga dalam hal penerimaan devisa setelah komoditas gas dan minyak bumi serta minyak kelapa sawit. Berdasarkan data tahun 2016, jumlah wisatawan mancanegara yang datang ke Indonesia sebesar 11.525.963 juta lebih atau tumbuh sebesar 10,79% dibandingkan tahun sebelumnya. Kekayaan alam dan budaya adalah komponen penting dalam pariwisata di Indonesia. Indonesia juga merupakan negara kepulauan terbesar dan berpenduduk terbanyak di dunia.


> 


Dari latar belakang diatas, proyek ini saya buat dengan tujuan memanfaatkan potensi-potensi tempat wisata yang ada di seluruh Indonesia. Semakin banyak orang-orang yang tau tempat-tempat wisata yang ada, maka akan semakin meningkat perekonomian yang ada di Indonesia.


> 


Referensi dari project overview di atas dapat dilihat dari link berikut ini [Pariwisata di Indonesia](https://id.wikipedia.org/wiki/Pariwisata_di_Indonesia)

### **Business Understanding**

Dari project overview di atas, sistem rekomendasi ini dikembangkan untuk menjawab pertanyaan berikut:

Problem Statement :

*   Dengan data-data yang dimiliki, bagaimana memberikan rekomendasi tempat wisata yang disukai oleh pengunjung ke pengunjung yang lain.


Goals :

*   Menghasilkan sistem rekomendasi yang akurat yang mengacu pada rating preferensi pengunjung sebelumnya

### **Data Understanding**

Dataset yang digunakan pada proyek sistem rekomendasi ini yaitu data Indonesia Tourism Destination yang didapatkan dari situs kaggle. Informasi dataset dapat dilihat pada [Indonesia Tourism Destination](https://www.kaggle.com/datasets/aprabowo/indonesia-tourism-destination?select=package_tourism.csv)

Unzip file data
"""

!unzip /content/archive.zip

"""Berikutnya, baca data-data di atas dengan menggunakan fungsi pandas.read_csv"""

import pandas as pd

places = pd.read_csv('/content/package_tourism.csv')
ratings = pd.read_csv('/content/tourism_rating.csv')
destinations = pd.read_csv('/content/tourism_with_id.csv')
users = pd.read_csv('/content/user.csv')

print('Jumlah data tempat wisata terdekat: ', len(places.Package.unique()))
print('Jumlah data penilaian tempat wisata: ', len(ratings.User_Id.unique()))
print('Jumlah data tempat wisata di 5 kota besar di Indonesia: ', len(destinations.Place_Id.unique()))
print('Jumlah data pengunjung tempat wisata: ', len(users.User_Id.unique()))

"""### **Univariate Exploratory Data Analysis**

Variabel-variabel pada Indonesia Tourism dataset adalah sebagai berikut :

*   places : yaitu rekomendasi tempat terdekat
*   ratings : penilaian yang diberikan pengunjung
*   destinations : yaitu informasi tempat wisata di 5 kota besar di indonesia
*   users : yaitu data pengunjung tempat wisata

##### **Place Variabel**

eksplorasi variabel accepts, yaitu rekomendasi tempat terdekat
"""

places.info()

places.head(5)

"""##### **Rating Variabel**

explorasi variabel rating, yaitu penilaian yang diberikan pengunjung
"""

ratings.info()

ratings.head()

ratings.describe()

"""Dari hasil output di atas, memberitahukan bahwa nilai minimun rating yaitu 1 dan nilai maksimum rating yaitu 5. Dengan begitu nilai rating berkisar 1 hingga 5.

##### **Destination Variabel**

explorasi variabel destination, yaitu informasi tempat wisata di 5 kota besar di Indonesia
"""

destinations.info()

destinations.head(5)

"""Drop kolom yang tidak dibutuhkan"""

destinations.drop(['Time_Minutes', 'Coordinate', 'Lat', 'Long', 'Unnamed: 11', 'Unnamed: 12'], axis=1, inplace=True)
destinations.head()

"""##### **User Variabel**

explorasi variabel user, yaitu data pengunjung wisata
"""

users.info()

"""### **Data Preprocessing**

##### **Menggabungkan Tempat Wisata**

menggabungkan beberapa file dengan fungsi concatenate berdasarkan Place_Id
"""

import numpy as np

# Menggabungkan seluruh Place_Id pada kategori Tempat Wisata
tourism_all = np.concatenate((
    ratings.Place_Id.unique(),
    destinations.Place_Id.unique()
))

# Mengurutkan data dan menghapus data yang saya
tourism_all = np.sort(np.unique(tourism_all))

print('Jumlah seluruh data tempat wisata berdasarkan Place_Id: ', len(tourism_all))

"""##### **Menggabungkan seluruh user**

menggabungkan beberapa file dengan fungsi concatenate berdasarkan User_Id
"""

# Menggabungkan seluruh userID
user_all = np.concatenate((
    ratings.User_Id.unique(),
    users.User_Id.unique()
))
 
# Menghapus data yang sama kemudian mengurutkannya
user_all = np.sort(np.unique(user_all)) 
 
print('Jumlah seluruh user: ', len(user_all))

"""##### **Mengetahui jumlah rating**"""

# Menggabungkan file place, rating, destination ke dalam dataframe tourism_info 
tourism_info = pd.concat([places, ratings, destinations])
 
# Menggabungkan dataframe rating dengan tourism_info berdasarkan nilai Place_Id
tourism = pd.merge(ratings, tourism_info , on='Place_Id', how='left')
tourism

"""Setelah melakukan merge, banyak sekali missing value. Cek missing value """

# Cek missing value dengan fungsi isnull()
tourism.isnull().sum()

"""Terdapat banyak missing value pada sebagian besar fitur. Hanya fitur User_Id, Place_Id dan Place_Rating_x yang memiliki 0 missing value. Berikutnya, menggabungkan rating berdasarkan Place_Id"""

tourism.groupby('Place_Id').sum()

"""##### **Menggabungkan Data dengan Fitur Nama Tempat Wisata**"""

# Definisikan dataframe rating ke dalam variabel all_tourism_rate
all_tourism_rate = ratings
all_tourism_rate

# Menggabungkan all tourism_rate dengan dataframe destination berdasarkan Place_Id
all_tourism = pd.merge(all_tourism_rate, destinations[['Place_Id', 'Place_Name', 'Description', 'Category', 'City']], on='Place_Id', how='left')
 
# Print dataframe all_tourism
all_tourism

"""### **Data Preparation**

Mengatasi Missing Value
"""

# Mengecek missing value pada dataframe all_tourism
all_tourism.isnull().sum()

# Mengurutkan tourism berdasarkan Place_Id kemudian memasukkannya ke dalam variabel fix_tourism
fix_tourism = all_tourism.sort_values('Place_Id', ascending=True)
fix_tourism

"""Sekarang, kita memiliki 10000 baris data. Untuk mengecek berapa jumlah tourism yang mencakup data tersebut, jalankan kode berikut"""

# Mengecek berapa jumlah fix_tourism
len(fix_tourism.Place_Id.unique())

"""mebuat variabel preparation yang berisi dataframe fix_tourism kemudian mengurutkan berdasarkan Place_Id"""

preparation = fix_tourism
preparation.sort_values('Place_Id')

# Membuang data duplikat pada variabel preparation
preparation = preparation.drop_duplicates('Place_Id')
preparation

"""Selanjutnya, kita perlu melakukan konversi data series menjadi list. Dalam hal ini, kita menggunakan fungsi tolist() dari library numpy"""

# Mengonversi data series Place_Id menjadi dalam bentuk list
tourism_id = preparation['Place_Id'].tolist()
 
# Mengonversi data series Place_Name menjadi dalam bentuk list
tourism_name = preparation['Place_Name'].tolist()
 
# Mengonversi data series Description menjadi dalam bentuk list
tourism_description = preparation['Description'].tolist()

# Mengonversi data series City menjadi dalam bentuk list
tourism_city = preparation['City'].tolist()
 
print(len(tourism_id))
print(len(tourism_name))
print(len(tourism_description))
print(len(tourism_city))

# Membuat dictionary untuk data ‘tourism_id’, ‘tourism_name’, dan ‘tourism_description’
tourism_new = pd.DataFrame({
    'id': tourism_id,
    'tourism_name': tourism_name,
    'description': tourism_description,
    'city': tourism_city
})
tourism_new

"""### **Model Development dengan Content Based Filtering**

cek data
"""

data = tourism_new
data.sample(5)

"""menggukan fungsi TFIDFVectorizer()"""

from sklearn.feature_extraction.text import TfidfVectorizer
 
# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()
 
# Melakukan perhitungan idf pada data city
tf.fit(data['city']) 
 
# Mapping array dari fitur index integer ke fitur nama
tf.get_feature_names()

"""Selanjutnya, lakukan fit dan transformasi ke dalam bentuk matriks"""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(data['city']) 
 
# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""Untuk menghasilkan vektor tf-idf dalam bentuk matriks, kita menggunakan fungsi todense()"""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""#### **Cosine Similarity**

menghitung derajat kesamaan (similarity degree) antar tourism dengan teknik cosine similarity
"""

from sklearn.metrics.pairwise import cosine_similarity
 
# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

"""Selanjutnya, mari kita lihat matriks kesamaan setiap tourism dengan menampilkan nama tourism dalam 5 sampel kolom (axis = 1) dan 10 sampel baris (axis=0)."""

# Membuat dataframe dari variabel cosine_sim dengan baris dan kolom berupa nama tourism
cosine_sim_df = pd.DataFrame(cosine_sim, index=data['tourism_name'], columns=data['tourism_name'])
print('Shape:', cosine_sim_df.shape)
 
# Melihat similarity matrix pada setiap resto
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""#### **Mendapatkan Rekomendasi**

*   Nama_tourism : Nama tourism (index kemiripan dataframe).
*   Similarity_data : Dataframe mengenai similarity yang telah kita definisikan sebelumnya.

*   Items : Nama dan fitur yang digunakan untuk mendefinisikan kemiripan, dalam hal ini adalah ‘tourism_name’ dan ‘city’.
*   k : Banyak rekomendasi yang ingin diberikan.
"""

def tourism_recommendations(nama_tourism, similarity_data=cosine_sim_df, items=data[['tourism_name', 'city']], k=5):

 
    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan    
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_tourism].to_numpy().argpartition(
        range(-1, -k, -1))
    
    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    # Drop nama_resto agar nama resto yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_tourism, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

"""Selanjutnya, terapkan kode di atas untuk menemukan rekomendasi tempat wisata yang mirip dengan KFC"""

data[data.tourism_name.eq('Pantai Greweng')]

# Mendapatkan rekomendasi tempat wisata yang mirip dengan Pantai Greweng
tourism_recommendations('Pantai Greweng')

"""### **Model Development dengan Collaborative Filtering**

import library yang dibutuhkan
"""

# Import library
import pandas as pd
import numpy as np 
from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt

"""memahami data rating, serta memasukkan nya ke variabel baru df"""

# Membaca dataset
 
df = ratings
df

"""melakukan persiapan data untuk menyandikan (encode) fitur ‘user’ dan ‘placeID’ ke dalam indeks integer"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = df['User_Id'].unique().tolist()
print('list userID: ', user_ids)
 
# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)
 
# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

"""Selanjutnya, lakukan hal yang sama pada fitur 'Place_Id'"""

# Mengubah Place_Id menjadi list tanpa nilai yang sama
tourism_ids = df['Place_Id'].unique().tolist()
 
# Melakukan proses encoding Place_Id
tourism_to_tourism_encoded = {x: i for i, x in enumerate(tourism_ids)}
 
# Melakukan proses encoding angka ke Place_Id
tourism_encoded_to_tourism = {i: x for i, x in enumerate(tourism_ids)}

"""Berikutnya, petakan User_Id dan Place_Id ke dataframe yang berkaitan"""

# Mapping User_Id ke dataframe user
df['users'] = df['User_Id'].map(user_to_user_encoded)
 
# Mapping Place_Id ke dataframe tourism
df['destinations'] = df['Place_Id'].map(tourism_to_tourism_encoded)

"""Terakhir, cek beberapa hal dalam data seperti jumlah user, jumlah tourism, dan mengubah nilai rating menjadi float"""

# Mendapatkan jumlah user
num_users = len(user_to_user_encoded)
print(num_users)
 
# Mendapatkan jumlah resto
num_tourism = len(tourism_encoded_to_tourism)
print(num_tourism)
 
# Mengubah rating menjadi nilai float
df['Place_Ratings'] = df['Place_Ratings'].values.astype(np.float32)
 
# Nilai minimum rating
min_rating = min(df['Place_Ratings'])
 
# Nilai maksimal rating
max_rating = max(df['Place_Ratings'])
 
print('Number of User: {}, Number of Tourism: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_tourism, min_rating, max_rating
))

"""#### **Membagi Data untuk Training dan Validasi**"""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df

"""bagi data train dan validasi dengan komposisi 80:20"""

# Membuat variabel x untuk mencocokkan data user dan destination menjadi satu value
x = df[['users', 'destinations']].values
 
# Membuat variabel y untuk membuat rating dari hasil 
y = df['Place_Ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""### **Proses Training**"""

class RecommenderNet(tf.keras.Model):
 
  # Insialisasi fungsi
  def __init__(self, num_users, num_resto, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_tourism = num_tourism
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.tourism_embedding = layers.Embedding( # layer embeddings tourism
        num_tourism,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.tourism_bias = layers.Embedding(num_tourism, 1) # layer embedding tourism bias
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    tourism_vector = self.tourism_embedding(inputs[:, 1]) # memanggil layer embedding 3
    tourism_bias = self.tourism_bias(inputs[:, 1]) # memanggil layer embedding 4
 
    dot_user_tourism = tf.tensordot(user_vector, tourism_vector, 2) 
 
    x = dot_user_tourism + user_bias + tourism_bias
    
    return tf.nn.sigmoid(x) # activation sigmoid

"""Selanjutnya, lakukan proses compile terhadap model"""

model = RecommenderNet(num_users, num_tourism, 50) # inisialisasi model
 
# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

# Memulai training
 
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""#### **Visualisasi Metrik**

plot metrik evaluasi dengan matplotlib
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Perhatikanlah, proses training model cukup smooth dan model konvergen pada epochs sekitar 100. Dari proses ini, kita memperoleh nilai error akhir sebesar sekitar 0.31 dan error pada data validasi sebesar 0.36.

#### **Mendapatkan Rekomendasi Tempat Wisata**
"""

tourism_df = tourism_new
df = pd.read_csv('/content/tourism_rating.csv')
 
# Mengambil sample user
user_id = df.User_Id.sample(1).iloc[0]
tourism_visited_by_user = df[df.User_Id == user_id]
 
tourism_not_visited = tourism_df[~tourism_df['id'].isin(tourism_visited_by_user.Place_Id.values)]['id'] 
tourism_not_visited = list(
    set(tourism_not_visited)
    .intersection(set(tourism_to_tourism_encoded.keys()))
)
 
tourism_not_visited = [[tourism_to_tourism_encoded.get(x)] for x in tourism_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_tourism_array = np.hstack(
    ([[user_encoder]] * len(tourism_not_visited), tourism_not_visited)
)

"""Selanjutnya, untuk memperoleh rekomendasi tempat wisata, gunakan fungsi model.predict() dari library Keras"""

ratings = model.predict(user_tourism_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_tourism_ids = [
    tourism_encoded_to_tourism.get(tourism_not_visited[x][0]) for x in top_ratings_indices
]
 
print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Tourism with high ratings from user')
print('----' * 8)
 
top_tourism_user = (
    tourism_visited_by_user.sort_values(
        by = 'Place_Ratings',
        ascending=False
    )
    .head(5)
    .Place_Id.values
)
 
tourism_df_rows = tourism_df[tourism_df['id'].isin(top_tourism_user)]
for row in tourism_df_rows.itertuples():
    print(row.tourism_name, ':', row.city)
 
print('----' * 8)
print('Top 10 tourism recommendation')
print('----' * 8)
 
recommended_tourism = tourism_df[tourism_df['id'].isin(recommended_tourism_ids)]
for row in recommended_tourism.itertuples():
    print(row.tourism_name, ':', row.city)

"""Dari hasil rekomendasi di atas, Semarang dan Yogyakarta menjadi kota yang paling tinggi ratingnya, dan top 10 tempat wisata yang direkomendasikan oleh sistem adalah kota Yogyakarta."""